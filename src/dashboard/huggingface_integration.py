#!/usr/bin/env python3
"""
ðŸ¤— PhytoAI Ã— Hugging Face Integration
Module pour charger les donnÃ©es MEGA depuis Hugging Face avec fallback intelligent
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Optional, Tuple
import logging

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@st.cache_data(ttl=3600, show_spinner=True)
def load_mega_from_huggingface(
    dataset_name: str = "phytoai/mega-phytotherapy-dataset",
    max_compounds: int = 10000,
    streaming: bool = True
) -> Tuple[pd.DataFrame, pd.DataFrame, dict]:
    """
    Charge les donnÃ©es MEGA depuis Hugging Face avec streaming intelligent
    
    Args:
        dataset_name: Nom du dataset sur Hugging Face
        max_compounds: Nombre max de composÃ©s Ã  charger (pour limiter la mÃ©moire)
        streaming: Utiliser le streaming ou charger tout
    
    Returns:
        Tuple[compounds_df, bioactivities_df, metadata]
    """
    
    try:
        # Tentative d'import des packages Hugging Face
        from datasets import load_dataset
        logger.info("ðŸ¤— Packages Hugging Face disponibles")
        
        # Configuration du chargement
        load_config = {
            "streaming": streaming,
            "trust_remote_code": True  # Pour datasets personnalisÃ©s
        }
        
        st.info(f"ðŸ”„ Chargement depuis Hugging Face: {dataset_name}")
        
        # Chargement du dataset
        try:
            dataset = load_dataset(dataset_name, **load_config)
            
            if streaming:
                # Mode streaming - charge par chunks
                compounds_data = []
                bioactivities_data = []
                
                # Charger les composÃ©s en streaming
                if 'compounds' in dataset:
                    st.write("ðŸ“Š Chargement des composÃ©s en streaming...")
                    compounds_stream = dataset['compounds']
                    
                    # Prendre un Ã©chantillon intelligent
                    count = 0
                    for compound in compounds_stream:
                        compounds_data.append(compound)
                        count += 1
                        
                        if count >= max_compounds:
                            break
                    
                    st.success(f"âœ… {len(compounds_data):,} composÃ©s chargÃ©s depuis Hugging Face")
                
                # Charger les bioactivitÃ©s si disponibles
                if 'bioactivities' in dataset:
                    st.write("ðŸ§ª Chargement des bioactivitÃ©s...")
                    bioactivities_stream = dataset['bioactivities']
                    
                    count = 0
                    for bioactivity in bioactivities_stream:
                        bioactivities_data.append(bioactivity)
                        count += 1
                        
                        if count >= max_compounds * 3:  # Plus de bioactivitÃ©s que de composÃ©s
                            break
                    
                    st.success(f"âœ… {len(bioactivities_data):,} bioactivitÃ©s chargÃ©es")
                
            else:
                # Mode complet - charge tout (attention mÃ©moire!)
                st.warning("âš ï¸ Chargement complet - peut Ãªtre lent avec gros datasets")
                
                compounds_data = list(dataset['compounds']) if 'compounds' in dataset else []
                bioactivities_data = list(dataset['bioactivities']) if 'bioactivities' in dataset else []
        
        except Exception as hf_error:
            logger.error(f"Erreur Hugging Face: {hf_error}")
            raise hf_error
        
        # Conversion en DataFrames
        compounds_df = pd.DataFrame(compounds_data) if compounds_data else pd.DataFrame()
        bioactivities_df = pd.DataFrame(bioactivities_data) if bioactivities_data else pd.DataFrame()
        
        # MÃ©tadonnÃ©es
        metadata = {
            'source': 'huggingface',
            'dataset_name': dataset_name,
            'compounds_count': len(compounds_df),
            'bioactivities_count': len(bioactivities_df),
            'streaming_used': streaming,
            'max_loaded': max_compounds
        }
        
        logger.info(f"âœ… DonnÃ©es chargÃ©es depuis Hugging Face: {metadata}")
        return compounds_df, bioactivities_df, metadata
        
    except ImportError:
        logger.warning("âš ï¸ Packages Hugging Face non installÃ©s")
        raise ImportError("Packages Hugging Face manquants")
        
    except Exception as e:
        logger.error(f"âŒ Erreur chargement Hugging Face: {e}")
        raise e

@st.cache_data(ttl=1800)
def load_local_fallback() -> Tuple[pd.DataFrame, pd.DataFrame, dict]:
    """
    Fallback sur les donnÃ©es locales si Hugging Face Ã©choue
    """
    try:
        # Chargement du dataset local (Ã©chantillon reprÃ©sentatif)
        compounds_df = pd.read_csv("real_compounds_dataset.csv")
        
        # Pas de bioactivitÃ©s sÃ©parÃ©es dans le fallback local
        bioactivities_df = pd.DataFrame()
        
        metadata = {
            'source': 'local_fallback',
            'compounds_count': len(compounds_df),
            'bioactivities_count': 0,
            'note': 'Ã‰chantillon reprÃ©sentatif local'
        }
        
        return compounds_df, bioactivities_df, metadata
        
    except Exception as e:
        logger.error(f"âŒ Erreur fallback local: {e}")
        raise e

def load_phytoai_data_smart(
    prefer_huggingface: bool = True,
    max_compounds: int = 10000
) -> Tuple[pd.DataFrame, pd.DataFrame, dict]:
    """
    Chargement intelligent des donnÃ©es PhytoAI avec stratÃ©gie de fallback
    
    Args:
        prefer_huggingface: Essayer Hugging Face d'abord
        max_compounds: Limite de composÃ©s pour Ã©viter surcharge mÃ©moire
    
    Returns:
        Tuple[compounds_df, bioactivities_df, metadata]
    """
    
    st.markdown("### ðŸ”„ Chargement Intelligent des DonnÃ©es PhytoAI")
    
    if prefer_huggingface:
        try:
            # Tentative Hugging Face
            st.info("ðŸŽ¯ StratÃ©gie #1: Hugging Face (dataset complet)")
            compounds_df, bioactivities_df, metadata = load_mega_from_huggingface(
                max_compounds=max_compounds
            )
            
            if len(compounds_df) > 0:
                st.success(f"ðŸŽ‰ SuccÃ¨s Hugging Face! {len(compounds_df):,} composÃ©s chargÃ©s")
                return compounds_df, bioactivities_df, metadata
            
        except Exception as e:
            st.warning(f"âš ï¸ Hugging Face indisponible: {str(e)[:100]}...")
            logger.warning(f"Fallback nÃ©cessaire: {e}")
    
    # Fallback sur donnÃ©es locales
    st.info("ðŸŽ¯ StratÃ©gie #2: Dataset local (Ã©chantillon reprÃ©sentatif)")
    try:
        compounds_df, bioactivities_df, metadata = load_local_fallback()
        st.success(f"âœ… Fallback rÃ©ussi! {len(compounds_df):,} composÃ©s locaux")
        return compounds_df, bioactivities_df, metadata
        
    except Exception as e:
        st.error(f"âŒ Ã‰chec des deux stratÃ©gies: {e}")
        # Dataset vide en dernier recours
        return pd.DataFrame(), pd.DataFrame(), {'source': 'empty', 'error': str(e)}

def display_data_source_info(metadata: dict):
    """
    Affiche les informations sur la source des donnÃ©es
    """
    source = metadata.get('source', 'unknown')
    
    if source == 'huggingface':
        st.success(f"""
        ðŸ¤— **Source: Hugging Face** (Dataset MEGA complet)
        - ðŸ“Š ComposÃ©s: {metadata.get('compounds_count', 0):,}
        - ðŸ§ª BioactivitÃ©s: {metadata.get('bioactivities_count', 0):,}
        - ðŸ”„ Streaming: {'Oui' if metadata.get('streaming_used') else 'Non'}
        - ðŸ“ˆ Limite chargÃ©e: {metadata.get('max_loaded', 'N/A'):,}
        """)
        
    elif source == 'local_fallback':
        st.info(f"""
        ðŸ’¾ **Source: Ã‰chantillon Local** (Fallback)
        - ðŸ“Š ComposÃ©s: {metadata.get('compounds_count', 0):,}
        - â„¹ï¸ Note: {metadata.get('note', 'DonnÃ©es reprÃ©sentatives')}
        """)
        
    elif source == 'empty':
        st.error(f"""
        âŒ **Aucune donnÃ©e disponible**
        - Erreur: {metadata.get('error', 'Inconnue')}
        """)

def get_enhanced_metrics(compounds_df: pd.DataFrame, metadata: dict) -> dict:
    """
    Calcule des mÃ©triques amÃ©liorÃ©es basÃ©es sur les donnÃ©es chargÃ©es
    """
    if len(compounds_df) == 0:
        return {}
    
    base_metrics = {
        'total_compounds': len(compounds_df),
        'data_source': metadata.get('source', 'unknown')
    }
    
    # MÃ©triques spÃ©cifiques selon les colonnes disponibles
    if 'mol_weight' in compounds_df.columns:
        base_metrics['avg_mol_weight'] = compounds_df['mol_weight'].mean()
        base_metrics['heavy_molecules'] = (compounds_df['mol_weight'] > 670).sum()
    
    if 'bioactivity_score' in compounds_df.columns:
        base_metrics['avg_bioactivity'] = compounds_df['bioactivity_score'].mean()
        base_metrics['high_activity'] = (compounds_df['bioactivity_score'] > 0.8).sum()
    
    if 'is_champion' in compounds_df.columns:
        base_metrics['champions'] = compounds_df['is_champion'].sum()
    
    return base_metrics

# Interface Streamlit pour tester l'intÃ©gration
def test_integration_ui():
    """
    Interface de test pour l'intÃ©gration Hugging Face
    """
    st.title("ðŸ§ª Test IntÃ©gration Hugging Face")
    
    st.markdown("### Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        prefer_hf = st.checkbox("PrÃ©fÃ©rer Hugging Face", value=True)
        max_compounds = st.slider("Max composÃ©s", 1000, 50000, 10000)
    
    with col2:
        dataset_name = st.text_input(
            "Dataset Hugging Face", 
            value="phytoai/mega-phytotherapy-dataset"
        )
    
    if st.button("ðŸš€ Tester Chargement"):
        with st.spinner("Chargement en cours..."):
            compounds_df, bioactivities_df, metadata = load_phytoai_data_smart(
                prefer_huggingface=prefer_hf,
                max_compounds=max_compounds
            )
        
        # Afficher les rÃ©sultats
        display_data_source_info(metadata)
        
        if len(compounds_df) > 0:
            st.markdown("### ðŸ“Š AperÃ§u des DonnÃ©es")
            st.dataframe(compounds_df.head())
            
            # MÃ©triques
            metrics = get_enhanced_metrics(compounds_df, metadata)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ComposÃ©s Total", metrics.get('total_compounds', 0))
            with col2:
                st.metric("Champions", metrics.get('champions', 'N/A'))
            with col3:
                st.metric("Poids Mol. Moyen", f"{metrics.get('avg_mol_weight', 0):.1f} Da")

if __name__ == "__main__":
    test_integration_ui() 